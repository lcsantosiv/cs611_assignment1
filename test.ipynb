{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05780faf-e44d-4fa2-a0b0-e1b85009ed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fe_1', 'fe_2', 'fe_3', 'fe_4', 'fe_5', 'fe_6', 'fe_7', 'fe_8', 'fe_9', 'fe_10', 'fe_11', 'fe_12', 'fe_13', 'fe_14', 'fe_15', 'fe_16', 'fe_17', 'fe_18', 'fe_19', 'fe_20', 'Customer_ID', 'snapshot_date']\n",
      "+-----------+-------------+----------------+\n",
      "|Customer_ID|snapshot_date|distinct_entries|\n",
      "+-----------+-------------+----------------+\n",
      "| CUS_0x1000|   2023-01-01|               1|\n",
      "| CUS_0x1000|   2023-02-01|               1|\n",
      "| CUS_0x1000|   2023-03-01|               1|\n",
      "| CUS_0x1000|   2023-04-01|               1|\n",
      "| CUS_0x1000|   2023-05-01|               1|\n",
      "| CUS_0x1000|   2023-06-01|               1|\n",
      "| CUS_0x1000|   2023-07-01|               1|\n",
      "| CUS_0x1000|   2023-08-01|               1|\n",
      "| CUS_0x1000|   2023-09-01|               1|\n",
      "| CUS_0x1000|   2023-10-01|               1|\n",
      "| CUS_0x1000|   2023-11-01|               1|\n",
      "| CUS_0x1000|   2023-12-01|               1|\n",
      "| CUS_0x1000|   2024-01-01|               1|\n",
      "| CUS_0x1000|   2024-02-01|               1|\n",
      "| CUS_0x1000|   2024-03-01|               1|\n",
      "| CUS_0x1000|   2024-04-01|               1|\n",
      "| CUS_0x1000|   2024-05-01|               1|\n",
      "| CUS_0x1000|   2024-06-01|               1|\n",
      "| CUS_0x1000|   2024-07-01|               1|\n",
      "| CUS_0x1000|   2024-08-01|               1|\n",
      "+-----------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQLExample\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "clickstream = spark.read.csv(\"data/feature_clickstream.csv\", header=True, inferSchema=True)\n",
    "clickstream.createOrReplaceTempView('clickstream')\n",
    "\n",
    "\n",
    "print(clickstream.columns)\n",
    "\n",
    "query = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        Customer_ID,\n",
    "        snapshot_date,\n",
    "        COUNT(snapshot_date) as distinct_entries\n",
    "    FROM clickstream\n",
    "    WHERE Customer_ID = \"CUS_0x1000\"\n",
    "    GROUP BY Customer_ID, snapshot_date\n",
    "    ORDER BY Customer_ID, snapshot_date\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f75f469d-6b41-4aef-8b88-a35d17ae18da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Customer_ID', 'Name', 'Age', 'SSN', 'Occupation', 'snapshot_date']\n",
      "+-----------+--------------+---+-----------+----------+-------------+\n",
      "|Customer_ID|          Name|Age|        SSN|Occupation|snapshot_date|\n",
      "+-----------+--------------+---+-----------+----------+-------------+\n",
      "| CUS_0x1000|Alistair Barrf| 18|913-74-1218|    Lawyer|   2023-05-01|\n",
      "+-----------+--------------+---+-----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "attributes = spark.read.csv(\"data/features_attributes.csv\", header=True, inferSchema=True)\n",
    "attributes.createOrReplaceTempView('attributes')\n",
    "\n",
    "print(attributes.columns)\n",
    "\n",
    "query = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM attributes\n",
    "    WHERE Customer_ID = \"CUS_0x1000\"\n",
    "    ORDER BY Customer_ID, snapshot_date\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0843f078-03f1-4a2f-a69c-e7b70af3e352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Customer_ID', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Type_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Credit_Mix', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age', 'Payment_of_Min_Amount', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Payment_Behaviour', 'Monthly_Balance', 'snapshot_date']\n",
      "+-----------+---------+\n",
      "|Customer_ID|instances|\n",
      "+-----------+---------+\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "financials = spark.read.csv(\"data/features_financials.csv\", header=True, inferSchema=True)\n",
    "financials.createOrReplaceTempView('financials')\n",
    "\n",
    "print(financials.columns)\n",
    "\n",
    "query = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM\n",
    "        (\n",
    "        SELECT\n",
    "        DISTINCT Customer_ID,\n",
    "        COUNT(*) OVER(PARTITION BY Customer_ID) as instances\n",
    "        FROM attributes\n",
    "        ) a\n",
    "    WHERE instances > 1\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "query.show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86d241cf-c6a5-4b73-ba96-9e67bf1130e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features_attributes',\n",
       " 'features_financials',\n",
       " 'feature_clickstream',\n",
       " 'lms_loan_daily']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"data\"\n",
    "csv_files = [f[:-4] for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "csv_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
